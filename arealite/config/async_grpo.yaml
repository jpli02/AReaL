# Basic experiment info
experiment_name: gsm8k-test
trial_name: my-trial
seed: 1
mode: ray
wandb:
  mode: disabled
  entity: null
  project: null
  name: null
  job_type: null
  group: null
  notes: null
  tags: null
  config: null
tensorboard:
  path: null

exp_ctrl:
  total_train_epochs: 5
  save_freq_epochs: 1
  save_freq_steps: null
  save_freq_secs: null
  ckpt_freq_epochs: null
  ckpt_freq_steps: null
  ckpt_freq_secs: 600
  eval_freq_epochs: null
  eval_freq_steps: null
  eval_freq_secs: null
  benchmark_steps: null
  benchmark_n_seqs: null

# whether to allow persistent servers
shutdown_server_on_exit: false

# Allocation and parallelism
allocation_mode: sglang.d4p1m1+d2p2m1
n_nodes: 1
n_gpus_per_node: 8

# Cluster configuration
ray_temp_path: /tmp/ray
cluster:
  cluster_name: local
  fileroot: /tmp/arealite/
  n_nodes: 1
  n_gpus_per_node: 8
  name_resolve:
    type: nfs
    nfs_record_root: /tmp/arealite/name_resolve/

# Datasets
train_dataset:
  path: openai/gsm8k
  name: main
  split: train
  batch_size: 128
  shuffle: True
  preprocessor:
    type: gsm8k_rl
    gsm8k:
      reward_mode: strict
valid_dataset: null

# Rollout config
rollout:
  collector:
    type: rlvr
    rlvr:
      reward_type: gsm8k
  num_workers: 1
  max_concurrent_rollouts: null
  max_head_offpolicyness: 4
  filter_reward_lb: -10000
  filter_reward_ub: 10000
  llm_client:
    server_backend: sglang
    schedule_policy: round_robin
    tokenizer_path: Qwen/Qwen2-0.5B-Instruct
    request_timeout: 3600
    request_retries: 3
  gconfig:
    n_samples: 16
    max_new_tokens: 512
    min_new_tokens: 0
    top_p: 1.0
    top_k: 1000000
    temperature: 1.0

# Trainer
trainer:
  type: grpo
  grpo:
    async_training: true
    actor:
      path: Qwen/Qwen2-0.5B-Instruct
      init_from_scratch: false
      gradient_checkpointing: false
      bf16: false
      optimizer:
        type: adam
        lr: 2.0e-05
        weight_decay: 0.05
        beta1: 0.9
        beta2: 0.95
        eps: 1.0e-05
        min_lr_ratio: 0.0
        lr_scheduler_type: constant
        warmup_steps_proportion: 0.001
        initial_loss_scale: 4294967296.0
        min_loss_scale: 1.0
        loss_scale_window: 5.0
        hysteresis: 2
        gradient_clipping: 1.0
      backend:
        type: hf
    ref: null
    mb_spec:
      max_tokens_per_mb: 10240
    # Algorithm
    group_adv_norm: False
    ppo_n_minibatches: 4
    eps_clip: 0.2
    c_clip: null
    reward_scaling: 10.0
    reward_bias: -0.5
    max_reward_clip: 20.0
    mask_no_eos_with_zero: false
    discount: 1.0
    gae_lambda: 1.0
    adv_norm: true
    kl_ctl: 0.0
    recompute_logprob: true
    use_decoupled_loss: true
    behav_imp_weight_cap: null

# LLM service
llm_service:
  server_backend: sglang
  served_model_name: null
  model_path: Qwen/Qwen2-0.5B-Instruct
  parallel:
    tensor_parallel_size: 1
    pipeline_parallel_size: 1
    data_parallel_size: 1
    use_sequence_parallel: false
  health_check_interval: 5
  startup_timeout: 300
  max_unhealth_count: 3
  graceful_shutdown_on_unhealthy: true
  sglang:
    disable_cuda_graph: false
    disable_radix_cache: false
    disable_cuda_graph_padding: false
    enable_nccl_nvls: false
    disable_outlines_disk_cache: false
    disable_custom_all_reduce: false
    disable_overlap_schedule: false
    enable_mixed_chunk: false
    enable_dp_attention: false
    enable_ep_moe: false
    enable_torch_compile: false
    torch_compile_max_bs: 32
    cuda_graph_max_bs: null
    cuda_graph_bs: null
    torchao_config: ""
    enable_nan_detection: false
    enable_p2p_check: false
    triton_attention_reduce_in_fp32: false
    triton_attention_num_kv_splits: 8
    num_continuous_decode_steps: 1
    enable_memory_saver: false
    allow_auto_truncate: false
    attention_backend: "flashinfer"
    sampling_backend: null
    context_length: 32768
    mem_fraction_static: 0.9
    max_running_requests: null
    chunked_prefill_size: -1
    max_prefill_tokens: 32768
    schedule_policy: "lpm"
    schedule_conservativeness: 1.0
    cpu_offload_gb: 0
    dtype: "float16"
    kv_cache_dtype: "auto"
    log_level: "warning"
    log_level_http: "warning"
    log_requests: false
    log_requests_level: 0
    show_time_cost: false
    enable_metrics: true
    decode_log_interval: 1